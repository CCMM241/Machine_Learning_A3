{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/thomasdorveaux/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langdetect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9fe77e0b0698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vader_lexicon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import zlib\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spotify = pd.read_csv('SpotifyFeatures.csv')\n",
    "lyrics = pd.read_csv('only_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging lyrics and the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spotify['track_name']=Spotify['track_name'].str.lower()\n",
    "Spotify['track_name']=Spotify['track_name'].str.strip()\n",
    "Spotify['artist_name']=Spotify['artist_name'].str.lower()\n",
    "Spotify['artist_name']=Spotify['artist_name'].str.strip()\n",
    "lyrics['song']=lyrics['song'].str.lower()\n",
    "lyrics['song']=lyrics['song'].str.strip()\n",
    "lyrics['artist']=lyrics['artist'].str.lower()\n",
    "lyrics['artist']=lyrics['artist'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics = Spotify.merge(lyrics, left_on=['track_name', 'artist_name'], right_on=['song', 'artist'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics =song_lyrics.sort_values(by=['popularity'],ascending=False)\n",
    "song_lyrics = song_lyrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics=song_lyrics.drop(['index','artist', 'song', 'link'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_lyrics(song_lyrics.iloc[675,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics):\n",
    "    new_lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', ' ', lyrics)\n",
    "    new_lyrics = new_lyrics.replace(\"\\n\", \" \")\n",
    "    #new_lyrics = new_lyrics.replace(\"\"\\\"\",\"\")\n",
    "    new_lyrics= new_lyrics.strip()\n",
    "    new_lyrics= new_lyrics.replace(\"    \", \" \")\n",
    "    new_lyrics= new_lyrics.replace(\"   \", \" \")\n",
    "    new_lyrics= new_lyrics.replace(\"  \", \" \")\n",
    "    new_lyrics = os.linesep.join([s for s in new_lyrics.splitlines() if s])\n",
    "    return(new_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compression_rate(lyrics):\n",
    "    original = lyrics.encode('utf-8')\n",
    "    compressed = zlib.compress(original)\n",
    "    decompressed = zlib.decompress(compressed)\n",
    "    \n",
    "    compression_rate = (len(original)-len(compressed))/len(original)\n",
    "    return compression_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply clean_lyrics function to text column\n",
    "song_lyrics['text'] = song_lyrics['text'].map(clean_lyrics)\n",
    "\n",
    "#Append new column with compression rate\n",
    "song_lyrics['compression_rate'] = song_lyrics['text'].map(get_compression_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ffb2f18c3f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Keep only english songs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msong_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msong_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect' is not defined"
     ]
    }
   ],
   "source": [
    "#Drop duplicates\n",
    "song_lyrics = song_lyrics.sort_values(by='popularity', ascending=False)\n",
    "song_lyrics = song_lyrics.drop_duplicates(subset='track_id', keep=\"first\")\n",
    "\n",
    "#Keep only english songs\n",
    "song_lyrics['language'] = song_lyrics['text'].map(detect)\n",
    "song_lyrics = song_lyrics[song_lyrics['language'] ==\"en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of sentment analysis (+,-,=) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia=SentimentIntensityAnalyzer()\n",
    "sentiment = pd.DataFrame(columns=('id','senti_positive', 'senti_neutral', 'senti_negative'))\n",
    "for i in range(len(song_lyrics['text'])):\n",
    "    num_positive = 0\n",
    "    num_negative = 0\n",
    "    num_neutral = 0\n",
    "    lyric= song_lyrics.iloc[i,-2]\n",
    "    for j in lyric.split():\n",
    "        comp = sia.polarity_scores(j)\n",
    "        comp = comp['compound']\n",
    "        #print(test)\n",
    "        if comp >= 0.5:\n",
    "            num_positive += 1\n",
    "            #print('positive:',i)\n",
    "        elif comp > -0.5 and comp < 0.5:\n",
    "            num_neutral += 1\n",
    "        else:\n",
    "            num_negative += 1\n",
    "        #print('negative:',i)\n",
    "    sentiment.loc[i] = (song_lyrics.iloc[i,3],num_positive,num_neutral,num_negative)\n",
    "#num_total = num_negative + num_neutral + num_positive\n",
    "#print('Total score:',num_total)\n",
    "#print('Negative score:',num_negative)\n",
    "#print('Neutral score:',num_neutral)\n",
    "#print('Positive score:',num_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics = song_lyrics.merge(sentiment, left_on=['track_id'], right_on=['id'])\n",
    "song_lyrics=song_lyrics.drop(['id'], axis=1)\n",
    "song_lyrics['senti_total']=song_lyrics['senti_positive']-song_lyrics['senti_negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile=song_lyrics['popularity'].quantile(np.arange(0, 1.01, 0.01).tolist())\n",
    "quantile=quantile.reset_index()\n",
    "quantile.rename(columns={'index':'quantile'}, inplace=True)\n",
    "sns.lineplot(quantile['popularity'],quantile['quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(quantile)\n",
    "quantile['cluster']=kmeans.predict(quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(quantile['popularity'],quantile['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one=quantile[quantile.cluster==1]\n",
    "two=quantile[quantile.cluster==2]\n",
    "three=quantile[quantile.cluster==3]\n",
    "zero=quantile[quantile.cluster==0]\n",
    "four=quantile[quantile.cluster==4]\n",
    "min_one=np.min(one['popularity'])\n",
    "max_one=np.max(one['popularity'])\n",
    "min_two=np.min(two['popularity'])\n",
    "max_two=np.max(two['popularity'])\n",
    "min_three=np.min(three['popularity'])\n",
    "max_three=np.max(three['popularity'])\n",
    "min_zero=np.min(zero['popularity'])\n",
    "max_zero=np.max(zero['popularity'])\n",
    "min_four=np.min(four['popularity'])\n",
    "max_four=np.max(four['popularity'])\n",
    "print(1,min_one,max_one)\n",
    "print(2,min_two,max_two)\n",
    "print(3,min_three,max_three)\n",
    "print(4,min_four,max_four)\n",
    "print(0,min_zero,max_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (song_lyrics['popularity'] >= 78)&(song_lyrics['popularity'] <=100),\n",
    "    (song_lyrics['popularity'] >= 55)&(song_lyrics['popularity'] <=77),\n",
    "    (song_lyrics['popularity'] >= 39)&(song_lyrics['popularity'] <=54),\n",
    "    (song_lyrics['popularity'] >= 19)&(song_lyrics['popularity'] <=38),\n",
    "    (song_lyrics['popularity'] >= 18)&(song_lyrics['popularity'] <=0)]\n",
    "choices = [4, 3, 2,1,0]\n",
    "song_lyrics['label'] = np.select(conditions, choices)\n",
    "song_lyrics.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Acousticness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_acou=song_lyrics['acousticness'].quantile(np.arange(0, 1.01, 0.01).tolist())\n",
    "quantile_acou=quantile_acou.reset_index()\n",
    "quantile_acou.rename(columns={'index':'quantile'}, inplace=True)\n",
    "sns.lineplot(quantile_acou['acousticness'],quantile_acou['quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(quantile_acou)\n",
    "quantile_acou['cluster']=kmeans.predict(quantile_acou)\n",
    "plt.scatter(quantile_acou['acousticness'],quantile_acou['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=quantile_acou[quantile_acou.cluster==0]\n",
    "one=quantile_acou[quantile_acou.cluster==1]\n",
    "two=quantile_acou[quantile_acou.cluster==2]\n",
    "three=quantile_acou[quantile_acou.cluster==3]\n",
    "four=quantile_acou[quantile_acou.cluster==4]\n",
    "\n",
    "min_zero=np.min(zero['acousticness'])\n",
    "max_zero=np.max(zero['acousticness'])\n",
    "min_one=np.min(one['acousticness'])\n",
    "max_one=np.max(one['acousticness'])\n",
    "min_two=np.min(two['acousticness'])\n",
    "max_two=np.max(two['acousticness'])\n",
    "min_three=np.min(three['acousticness'])\n",
    "max_three=np.max(three['acousticness'])\n",
    "\n",
    "print(0,min_zero,max_zero)\n",
    "print(1,min_one,max_one)\n",
    "print(2,min_two,max_two)\n",
    "print(3,min_three,max_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_acou = [\n",
    "    (song_lyrics['acousticness'] >= 0.6158599999999996)&(song_lyrics['acousticness'] <=0.995),\n",
    "    (song_lyrics['acousticness'] >= 0.251)& (song_lyrics['acousticness'] <=0.594),\n",
    "    (song_lyrics['acousticness'] >= 0.0363)&(song_lyrics['acousticness'] <=0.239),\n",
    "    (song_lyrics['acousticness'] >= 1.39e-06)&(song_lyrics['acousticness'] <=0.03276299999999999)]\n",
    "choices_acou = [3, 2,1,0]\n",
    "song_lyrics['label_acou'] = np.select(conditions_acou, choices_acou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analysing features distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(song_lyrics['duration_ms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 5, figsize=(14, 8), sharex=False)\n",
    "sns.distplot(song_lyrics['popularity'],ax=axes[0,0])\n",
    "sns.distplot(song_lyrics['acousticness'],ax=axes[0,1])\n",
    "sns.distplot(song_lyrics['danceability'],ax=axes[0,2])\n",
    "sns.distplot(song_lyrics['energy'],ax=axes[0,3])\n",
    "sns.distplot(song_lyrics['instrumentalness'],ax=axes[0, 4])\n",
    "sns.distplot(song_lyrics['liveness'],ax=axes[1,0])\n",
    "sns.distplot(song_lyrics['loudness'],ax=axes[1,1])\n",
    "sns.distplot(song_lyrics['speechiness'],ax=axes[1,2])\n",
    "sns.distplot(song_lyrics['valence'],ax=axes[1,3])\n",
    "sns.distplot(song_lyrics['tempo'],ax=axes[1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning duration_ms to improve this feature\n",
    "ln_duration_ms = np.log(song_lyrics['duration_ms'])\n",
    "ln_liveness = np.log(song_lyrics['liveness'])\n",
    "#sns.distplot(ln_duration_ms)\n",
    "#sns.distplot(ln_liveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(song_lyrics['popularity'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(song_lyrics['compression_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['senti_positive'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['senti_neutral'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['senti_total'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['speechiness'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['speechiness'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['valence'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['compression_rate'] )\n",
    "#plt.scatter(song_lyrics['popularity'],song_lyrics['acousticness'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming data before classification\n",
    "\n",
    "# track features\n",
    "genre = song_lyrics['genre']\n",
    "artist_name = song_lyrics['artist_name']\n",
    "track_name = song_lyrics['track_name']\n",
    "track_id = song_lyrics['track_id']\n",
    "\n",
    "# spotify features\n",
    "popularity = song_lyrics['popularity']\n",
    "acousticness = song_lyrics['acousticness']\n",
    "class_acou = song_lyrics['label_acou']\n",
    "danceability = song_lyrics['danceability']\n",
    "duration_ms = song_lyrics['duration_ms']  # ln_duration_ms should be used for any models (centered distribution)\n",
    "energy = song_lyrics ['energy']\n",
    "instrumentalness = song_lyrics['instrumentalness']\n",
    "key = song_lyrics['key']\n",
    "liveness = song_lyrics['liveness']  #ln_liveness should be better also\n",
    "loudness = song_lyrics['loudness']\n",
    "mode = song_lyrics['mode']\n",
    "speechiness = song_lyrics['speechiness']\n",
    "tempo = song_lyrics['tempo']\n",
    "time_signature = song_lyrics['time_signature']\n",
    "valence = song_lyrics['valence']\n",
    "\n",
    "# sentimental features\n",
    "text = song_lyrics['text']\n",
    "compression_rate = song_lyrics['compression_rate']\n",
    "senti_positive = song_lyrics['senti_positive']\n",
    "senti_neutral = song_lyrics['senti_neutral']\n",
    "senti_negative = song_lyrics['senti_negative']\n",
    "senti_total = song_lyrics['senti_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding discrete data\n",
    "\n",
    "# track features\n",
    "genre_encoded = pd.get_dummies(genre,prefix='genre', dummy_na=False)\n",
    "artist_name_encoded = pd.get_dummies(genre,prefix='artist_name', dummy_na=False)\n",
    "\n",
    "# spotify features \n",
    "key_encoded = pd.get_dummies(key,prefix='key', dummy_na=False)\n",
    "mode_encoded = pd.get_dummies(mode,prefix='mode', dummy_na=False)\n",
    "time_signature_encoded = pd.get_dummies(time_signature,prefix='time_signature', dummy_na=False)\n",
    "class_acou_encoded = pd.get_dummies(time_signature,prefix='class_acou', dummy_na=False)\n",
    "\n",
    "#sentimal features \n",
    "senti_positive_enoded = pd.get_dummies(senti_positive,prefix='senti_positive', dummy_na=False)\n",
    "senti_neutral_encoded = pd.get_dummies(senti_neutral,prefix='senti_neutral', dummy_na=False)\n",
    "senti_negative_encoded = pd.get_dummies(senti_negative,prefix='senti_negative', dummy_na=False)\n",
    "senti_total_encoded = pd.get_dummies(senti_total,prefix='senti_total', dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
